{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "MNIST = input_data.read_data_sets(\"MNIST_data\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack([img.reshape(-1,) for img in MNIST.train.images])\n",
    "Y_train = MNIST.train.labels\n",
    "X_test = np.vstack([img.reshape(-1,) for img in MNIST.test.images])\n",
    "Y_test = MNIST.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the train data for two digit classes 2 and 3\n",
    "train_data = {}\n",
    "train_ind = []\n",
    "for i in range(len(Y_train)):\n",
    "    if Y_train[i] == 2 or Y_train[i] == 3:\n",
    "        train_ind.append(i)\n",
    "train_data['data'] = [X_train[i] for i in train_ind]\n",
    "train_data['target'] = [Y_train[i] for i in train_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the test data for two digit classes 2 and 3\n",
    "test_data = {}\n",
    "test_ind = []\n",
    "for i in range(len(Y_test)):\n",
    "    if Y_test[i] == 2 or Y_test[i] == 3:\n",
    "        test_ind.append(i)\n",
    "test_data['data'] = [X_test[i] for i in test_ind]\n",
    "test_data['target'] = [Y_test[i] for i in test_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = 'lbfgs')\n",
    "#Train model\n",
    "logreg.fit(train_data['data'], train_data['target'])\n",
    "logreg_predictions = logreg.predict(test_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9789422135161606"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy score:\n",
    "logreg.score(test_data['data'], test_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(test_data['target'], logreg_predictions)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97577519, 0.02422481],\n",
       "       [0.01782178, 0.98217822]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The normalized confusion matrix:\n",
    "cm_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest-neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train data into train and validation set:\n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(train_data['data'] , train_data['target'] , test_size=0.1, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=99.19%\n",
      "k=3, accuracy=99.55%\n",
      "k=5, accuracy=99.55%\n",
      "k=7, accuracy=99.37%\n"
     ]
    }
   ],
   "source": [
    "# Train our classifier and find the optimal value of k\n",
    "# initialize the values of k for our k-Nearest Neighbor classifier\n",
    "# to save time, we can test only odd values of k, instead of testing consecutive k\n",
    "# create a list to store the accuracies for each value of k\n",
    "accuracies = []\n",
    "kVals = range(1, 8, 2)\n",
    "# loop over various values of `k` for the k-Nearest Neighbor classifier\n",
    "for k in kVals:\n",
    "    # train the k-Nearest Neighbor classifier with the current value of `k`\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(trainData, trainLabels)\n",
    "    # evaluate the model using validation data and update the accuracies list\n",
    "    score = knn.score(valData, valLabels)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    accuracies.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3 achieved highest accuracy of 99.55% on validation data\n"
     ]
    }
   ],
   "source": [
    "# find the value of k that has the largest accuracy - this is usable in case we considered more values of ks\n",
    "i = np.argmax(accuracies)\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i], accuracies[i] * 100))\n",
    "# re-train our classifier using the best k value and predict the labels of the\n",
    "# test data\n",
    "best_knn = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "best_knn.fit(trainData, trainLabels)\n",
    "predictions = best_knn.predict(test_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accuracy score on the test set\n",
    "knn_score = knn.score(test_data['data'], test_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965719882468168"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION ON TESTING DATA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          2       1.00      1.00      1.00      1032\n",
      "          3       1.00      1.00      1.00      1010\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show a final classification report demonstrating the accuracy of the classifier\n",
    "# for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(test_data['target'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results:\n",
    "Accuracy scores for the two model:\n",
    "- k-neighbor-neighbor: 99.66 %\n",
    "- logistic regression: 97.89 %\n",
    "\n",
    "Based on the accuracy scores, we can conclude that knn nearest neighbor performs slightly better than logistic regression in classifying \"2\" and \"3\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
